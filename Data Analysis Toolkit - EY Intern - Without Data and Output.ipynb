{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Pandas\n",
    "import numpy as np # Numpy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt # Matplotlibrary\n",
    "import seaborn as sns # Seaborn Library\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\") # 设置绘图风格\n",
    "\n",
    "\n",
    "# 将以下此代码输入你要画的图前可以避免无法显示中文\n",
    "from pylab import *\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style({'font.sans-serif':['SimHei','Arial']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7f6ce3a07046>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 网页数据变为字符串\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# 网页数据变为字符串\n",
    "data = str(data,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_Znorm(df, *cols) 标准化数据\n",
    "\n",
    "输入：*cols：list-like，即需要正则化的列。\n",
    "\n",
    "输出：标准化后的df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Znorm(df, *cols):\n",
    "    df_n = df.copy()\n",
    "    for col in cols:\n",
    "        u = df_n[col].mean()\n",
    "        std = df_n[col].std()\n",
    "        df_n[col + '_Zn'] = (df_n[col] - u) / std\n",
    "    return(df_n)\n",
    "# 创建函数，标准化数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map_result(df,col) 最快捷的map方法\n",
    "\n",
    "输入：\n",
    "col: 列名，函数将该列文字等分类变量转换为1，2，3，4•••无顺序含义的数值\n",
    "\n",
    "输出：\n",
    "map过后的df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最快的分类变量mapping方法\n",
    "def map_result(df,col):\n",
    "    df_n = df.copy()\n",
    "    class_mapping = {label: idx for idx, label in enumerate(np.unique(df_n[col]))}\n",
    "    df_n[col] = df_n[col].map(class_mapping)\n",
    "    return df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## choose_object(df) 与 choose_numeric(df)\n",
    "\n",
    "输入：待选df\n",
    "\n",
    "输出：选择后的df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择分类变量列\n",
    "def choose_object(df):\n",
    "    df_n = df.copy()\n",
    "    cols = df_n.columns\n",
    "    new_cols_list = [col for col in cols if str(df_n[col].dtype) == 'object']\n",
    "    return df_n[new_cols_list]\n",
    "\n",
    "# 选择数值型变量列\n",
    "def choose_numeric(df):\n",
    "    df_n = df.copy()\n",
    "    cols = df_n.columns\n",
    "    new_cols_list = [col for col in cols if str(df_n[col].dtype) != 'object']\n",
    "    return df_n[new_cols_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T06:43:25.110614Z",
     "start_time": "2021-09-23T06:43:25.092661Z"
    }
   },
   "outputs": [],
   "source": [
    "# 用原有数据分布fillna（）\n",
    "def random_choice_fillna(df,col,seed):\n",
    "    from numpy.random import default_rng\n",
    "    import numpy as np\n",
    "    counts = pd.Series(df[col].value_counts()/df[col].value_counts().sum())\n",
    "    list1 = counts.index\n",
    "    list2 = counts.values\n",
    "    rng = default_rng()\n",
    "    return rng.choice(list1,p=list2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单描述分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_statistics_table_num(df) 创建数值型统计量\n",
    "\n",
    "输出：统计量的dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有初步统计变量的生成 使用于numeric\n",
    "\"\"\"\n",
    "automatically generate a report which contains all the statistics of the factors in the DataFrame\n",
    "\"\"\"\n",
    "def create_statistics_table_num(df):\n",
    "    df_n = df.copy()\n",
    "    describe = df_n.describe() \n",
    "    # print(type(describe))\n",
    "    cols = df_n.columns\n",
    "    temp = pd.DataFrame(index=['range','median','variance','skew','kurt','Coef'],columns=cols)\n",
    "    for col in cols:\n",
    "        list_temp = []\n",
    "        list_temp.append(df_n[col].max()-df_n[col].min())\n",
    "        list_temp.append(df_n[col].median())\n",
    "        list_temp.append(df_n[col].var())\n",
    "        list_temp.append(df_n[col].skew())\n",
    "        list_temp.append(df_n[col].kurt())  \n",
    "        list_temp.append(df_n[col].std()/df_n[col].mean())       \n",
    "        temp[col] = list_temp\n",
    "    # print(temp)\n",
    "    describe = pd.concat([describe,temp])\n",
    "    return describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_statistics_table_cat(df) 创建分类变量的统计量\n",
    "\n",
    "输出：统计量dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T22:02:16.955221Z",
     "start_time": "2021-10-29T22:02:16.947255Z"
    }
   },
   "outputs": [],
   "source": [
    "# The variation ratio is a simple measure of statistical dispersion in nominal distributions; \n",
    "# it is the simplest measure of qualitative variation.\n",
    "# It is defined as the proportion of cases which are not in the mode category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T20:05:18.967621Z",
     "start_time": "2021-09-22T20:05:18.957673Z"
    }
   },
   "outputs": [],
   "source": [
    "# 统计变量的生成 适用于 catagory\n",
    "\"\"\"\n",
    "automatically generate a report which contains some statistics(Here:Variation Ratio) of the factors in the DataFrame\n",
    "\n",
    "remenber: Make sure no chinese symbol or words exist when you are calculating Variation Ratio.\n",
    "\"\"\"\n",
    "def create_statistics_table_cat(df):\n",
    "    from scipy.stats import mode\n",
    "    df_n = df.copy()\n",
    "    cols = df_n.columns\n",
    "    print('col name\\t\\tmissing num\\t\\tmissing %')\n",
    "    for string in cols:\n",
    "        missing_num = df_n[string].isnull().sum()\n",
    "        missing_percent = df_n[string].isnull().sum() / len(df_n[string])\n",
    "        print(string+f'\\t\\t{missing_num}\\t\\t{missing_percent}')  \n",
    "    temp = pd.DataFrame(index=['Variation Ratio'],columns=cols)\n",
    "    for col in cols:\n",
    "        list_temp = []\n",
    "        list_temp.append(1-mode(df_n[col])[1][0]/len(df_n[col]))\n",
    "        temp[col] = list_temp\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## auto_html_report(df, title, output_file) 创建数值型完整的html分析报告\n",
    "\n",
    "输入：解释如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T20:00:31.887901Z",
     "start_time": "2021-09-22T20:00:31.868444Z"
    }
   },
   "outputs": [],
   "source": [
    "# 自动生成的html文档 常适用于numeric\n",
    "\"\"\"\n",
    "df:DataFrame,it's better to input data with less than 15 columns for speed purpose\n",
    "title: string, the title of the html like ' Yerushalayim_TRANSACTION_NUMERIC_DATA'\n",
    "output_file: string, the name of the output file like 'Yerushalayim_TRANSACTION_AUTO_REPORT_NUMERIC.html'\n",
    "\"\"\"\n",
    "def auto_html_report(df, title, output_file):\n",
    "    df_n = df.copy()\n",
    "    import pandas_profiling  \n",
    "    profile=df_n.profile_report(title=title)  \n",
    "    profile.to_file(output_file=output_file)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 时间序列 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time_series_index(df, col) 将dataframe的索引设置为时间索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间序列预处理 index\n",
    "\"\"\"\n",
    "col: the column name of the time series like \"Transaction_Date\"\n",
    "\"\"\"\n",
    "def time_series_index(df, col):\n",
    "    df_n = df.copy()\n",
    "    df_n.index=pd.to_datetime(df_n[col])\n",
    "    return df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dickey-Fuller test 检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移动平均图\n",
    "def draw_trend(timeseries, size):\n",
    "    f = plt.figure(facecolor='white')\n",
    "    # 对size个数据进行移动平均\n",
    "    rol_mean = timeseries.rolling(window=size).mean()\n",
    "    # 对size个数据移动平均的方差\n",
    "    rol_std = timeseries.rolling(window=size).std()\n",
    " \n",
    "    timeseries.plot(color='blue', label='Original')\n",
    "    rol_mean.plot(color='red', label='Rolling Mean')\n",
    "    rol_std.plot(color='black', label='Rolling standard deviation')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "\n",
    "def draw_ts(timeseries):\n",
    "    f = plt.figure(facecolor='white')\n",
    "    timeseries.plot(color='blue')\n",
    "    plt.show()\n",
    "\n",
    "#Dickey-Fuller test:\n",
    "def teststationarity(ts):\n",
    "    dftest = adfuller(ts)\n",
    "    # 对上述函数求得的值进行语义描述\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomcolor():\n",
    "    colorArr = ['1','2','3','4','5','6','7','8','9','A','B','C','D','E','F']\n",
    "    color = \"\"\n",
    "    for i in range(6):\n",
    "        color += colorArr[random.randint(0,14)]\n",
    "    return \"#\"+color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hist_diagram(df, col) 直方图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "直方图\n",
    "method: count\n",
    "remenber: If there are too many different situations, you can change figsize or aspect to make it clear enough.\n",
    "\"\"\"\n",
    "def hist_diagram(df, col):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.catplot(x=col, kind=\"count\", palette=\"ch:.25\", aspect=2,data=df)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kde_diagram(df, col, color) 单变量密度图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "单变量密度图\n",
    "color: deeppink; dodgerblue\n",
    "remember: there are various kind of colors in the website of seaborn. please check if you need more\n",
    "\"\"\"\n",
    "def kde_diagram(df, col, color):\n",
    "    df_n = df.copy()\n",
    "    sns.kdeplot(df_n[col], shade=True, color=color, label=col, alpha=.7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## double_hist_compare(df, sort_col, x1_col, x2_col, y_col) 分类横向直方图——双变量比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "分类横向直方图——双变量比较\n",
    "sort_col: perform ascending based on this column \n",
    "x1_col: first variable\n",
    "x2_col: second variable\n",
    "y_col: catagory\n",
    "\"\"\"\n",
    "def double_hist_compare(df, sort_col, x1_col, x2_col, y_col):\n",
    "    #sns.set(style=\"whitegrid\")  \n",
    "    # Initialize the matplotlib figure  \n",
    "    df_n = df.copy()\n",
    "    f, ax = plt.subplots(figsize=(9, 15))  \n",
    "    df_n_sorted = df_n.sort_values(sort_col, ascending=False)  \n",
    "\n",
    "    sns.set_color_codes(\"pastel\")  \n",
    "    sns.barplot(x= x1_col, y= y_col, data=df_n_sorted,label= x1_col, color=\"b\")  \n",
    "\n",
    "    sns.set_color_codes(\"muted\")  \n",
    "    sns.barplot(x= x2_col, y= y_col, data=df_n_sorted,label= x2_col, color=\"b\")  \n",
    "\n",
    "    ax.legend(ncol=2, loc=\"lower right\", frameon=True)  \n",
    "    xlabel = \"%s & %s per department\" % (x1_col,x2_col)\n",
    "    ax.set(ylabel=\"\",xlabel=xlabel)  \n",
    "    sns.despine(left=True, bottom=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time_series(df,col1,col2, hue) 折线图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "折线图展现时间序列\n",
    "col1: the column of the time series like \"Transaction_Date\"\n",
    "col2: what you want to show like \"Approved_Amount\"\n",
    "hue: column to catagorize like \"BU\"\n",
    "\"\"\"\n",
    "def time_series(df,col1,col2, hue):\n",
    "    df_n = df.copy()\n",
    "    #sns.set(style=\"darkgrid\") \n",
    "    plt.figure(figsize=(26,20), dpi= 80)  \n",
    "    sns.set_style({'font.sans-serif':['SimHei','Arial']})\n",
    "    # Plot the responses for different events and regions  \n",
    "    sns.lineplot(x=col1, y=col2, hue=hue, data=data_1)  \n",
    "    plt.xticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## corr_matrix(df) 相关系数矩阵 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "相关系数矩阵\n",
    "\n",
    "\"\"\"\n",
    "def corr_matrix(df):\n",
    "    df_n = df.copy()\n",
    "    plt.figure(figsize=(12,10), dpi= 80)  \n",
    "    sns.set_style({'font.sans-serif':['SimHei','Arial']})\n",
    "    sns.heatmap(df_n.corr(), xticklabels=df_n.corr().columns, yticklabels=df_n.corr().columns, cmap='coolwarm', center=0, annot=True)  \n",
    "    plt.title('Correlogram', fontsize=22)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scatter_double(df,x_col,y_col,hue_col,size_col) 二分类变量散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "两分类变量，两数值变量的散点图\n",
    "x_col: x轴的列\n",
    "y_col: y轴的列\n",
    "hue_col : 拿什么列来分类\n",
    "size_col : 拿什么列的数值来作为大小\n",
    "\"\"\"\n",
    "def scatter_double(df,x_col,y_col,hue_col,size_col):\n",
    "    df_n = df.copy()\n",
    "    f, ax = plt.subplots(figsize=(13, 13)) \n",
    "    sns.set_style({'font.sans-serif':['SimHei','Arial']})\n",
    "    sns.despine(f, left=True, bottom=True)  \n",
    "    clarity_ranking = list(set(list(df_n[hue_col])))\n",
    "    sns.scatterplot(x=x_col, y=y_col,  \n",
    "                    hue=hue_col, size=size_col,  \n",
    "                    palette=\"Paired\",  \n",
    "                    hue_order=clarity_ranking,  \n",
    "                    sizes=(1, 16), linewidth=0,  \n",
    "                    data=df_n, ax=ax)  \n",
    "    ax.legend(loc=\"upper right\", frameon=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boxplot_scatter(df, x_col, y_col, hue_col) 箱线图与散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "箱线图+散点图\n",
    "x_col: x轴的列\n",
    "y_col: y轴的列\n",
    "hue_col : 拿什么列来分类\n",
    "\"\"\"\n",
    "def boxplot_scatter(df, x_col, y_col, hue_col):\n",
    "    df_n = df.copy()\n",
    "    # Draw Plot  \n",
    "    plt.figure(figsize=(14,10), dpi= 80)  \n",
    "    sns.boxplot(x=x_col, y=y_col, data=df_n, hue=hue_col, palette=\"Set2\")  \n",
    "    sns.stripplot(x=x_col, y=y_col, data=df_n, size=4, jitter=0.05)  #color='black'\n",
    "\n",
    "    for i in range(len(df_n[hue_col].unique())-1):  \n",
    "        plt.vlines(i+.5, 10, 45, linestyles='solid', alpha=0.2)  #colors='gray'\n",
    "    title = 'Box Plot of %s by %s'% (y_col, x_col)\n",
    "    plt.title(title, fontsize=22)  \n",
    "    plt.legend(title=hue_col)  \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正态化检验与正态转换\n",
    "#### 非所有均能转换为正态，boxcox可以接近正态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check_normality(testData) 正太检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断是否为正态\n",
    "import scipy\n",
    "from scipy.stats import f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "# additional packages\n",
    "#from statsmodels.stats.diagnostic import lillifors\n",
    " \n",
    "def check_normality(testData):\n",
    "    #20<样本数<50用normal test算法检验正态分布性\n",
    "    if 20<len(testData) <50:\n",
    "        p_value=stats.normaltest(testData)[1]\n",
    "        if p_value<0.05:\n",
    "            print(\"use normaltest\")\n",
    "            print(\"data are not normal distributed\")\n",
    "            return  False\n",
    "        else:\n",
    "            print(\"use normaltest\")\n",
    "            print(\"data are normal distributed\")\n",
    "            return True\n",
    "     \n",
    "    #样本数小于50用Shapiro-Wilk算法检验正态分布性\n",
    "    if len(testData) <50:\n",
    "        p_value= stats.shapiro(testData)[1]\n",
    "        if p_value<0.05:\n",
    "            print (\"use shapiro:\")\n",
    "            print (\"data are not normal distributed\")\n",
    "            return  False\n",
    "        else:\n",
    "            print (\"use shapiro:\")\n",
    "            print (\"data are normal distributed\")\n",
    "            return True\n",
    "     \n",
    "    if len(testData) >50: \n",
    "        p_value= stats.kstest(testData,'norm')[1]\n",
    "        if p_value<0.05:\n",
    "            print (\"use kstest:\")\n",
    "            print (\"data are not normal distributed\")\n",
    "            return  False\n",
    "        else:\n",
    "            print (\"use kstest:\")\n",
    "            print (\"data are normal distributed\")\n",
    "            return True\n",
    " \n",
    " \n",
    "#对所有样本组进行正态性检验\n",
    "def NormalTest(list_groups):\n",
    "    for group in list_groups:\n",
    "        #正态性检验\n",
    "        status=check_normality(group1)\n",
    "        if status==False :\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算参数\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "  \n",
    "x = np.random.randn(10000)\n",
    "mu = np.mean(x, axis=0)\n",
    "sigma = np.std(x, axis=0)\n",
    "skew = stats.skew(x)\n",
    "kurtosis = stats.kurtosis(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换正态的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_Transform_boxcox(df, *cols) boxcox将数据尽可能往正态靠拢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转换为正态\n",
    "from scipy import stats\n",
    "def data_Transform_boxcox(df, *cols):\n",
    "    df_n = df.copy()\n",
    "    for col in cols:\n",
    "        min_num = df_n[col].min()\n",
    "        print(min_num)\n",
    "        if df_n[col].min()<=0:\n",
    "            df_n[col] = df_n[col]-min_num+1\n",
    "        xt, _ = stats.boxcox(df_n[col])\n",
    "        df_n[col+'_Boxcox'] = xt\n",
    "    return df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform_norm(df, *cols, method) 其他数据变化的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "method : please choose the method you want\n",
    "\"\"\"\n",
    "# 其他处理变换\n",
    "def data_Transform(df, *cols, method):\n",
    "    df_n = df.copy()\n",
    "    for col in cols:\n",
    "        if method == 'log':\n",
    "            xt = np.log(df_n[col])\n",
    "        elif method == 'sqrt':\n",
    "            xt = np.sqrt(df_n[col])\n",
    "        elif method == 'reciprocal':\n",
    "            xt = 1/df_n[col]\n",
    "        elif method == 'arcsin_sqrt':\n",
    "            xt = np.arcsin(np.sqrt(df_n[col]))\n",
    "        df_n[col+'_log'] = xt\n",
    "    return df_n\n",
    "\n",
    "\n",
    "\n",
    "#如果不是正态转换为正态\n",
    "def transform_norm(df, *cols, method):\n",
    "    df_n = df.copy()\n",
    "    for col in cols:\n",
    "        result=check_normality(df_n[col])\n",
    "        if result == False:\n",
    "            df_n[col] = data_Transform(df_n, col, method)\n",
    "            return df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方差分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# 单因素方差分析\n",
    "def single_anova(df, y_col, x_col):\n",
    "    formula = \"%s~%s\" % (y_col,x_col)\n",
    "    model = ols(formula,df).fit()\n",
    "    anovat = anova_lm(model)\n",
    "    return anovat\n",
    "\n",
    "# 双因素方差分析/多因素方差分析\n",
    "# 多变量——Expense_Type+BU\n",
    "def multiple_anova(df,y_col, x_col1,x_col2):\n",
    "    data = df\n",
    "    \n",
    "    formula = '%s~%s + %s'%(y_col,x_col1,x_col2)\n",
    "    anova_results = anova_lm(ols(formula,data).fit())\n",
    "    return anova_results\n",
    "\n",
    "\n",
    "# 多重比较\n",
    "def multiple_compare(df,col1,col2):\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "    result = pairwise_tukeyhsd(df[col1], df[col2])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "#selector=SelectKBest(score_func=f_classif,k=1)\n",
    "#selector.fit(company_used_features[[\"Expense_type\",\"date\",\"Region\",\"approvers\",\"Payment_methods\",\"BU\"]],company_used_features['Approved_Amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程——个人行为数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  金额部分 person_amount_feature(df,id_person,amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 个人行为数据——金额部分所有特征\n",
    "\"\"\"\n",
    "id_person: 员工所在列的列名\n",
    "amount: 金额列的列名\n",
    "\n",
    "输出：员工金额部分dataframe\n",
    "\"\"\"\n",
    "\n",
    "def person_amount_feature(df,id_person,amount):\n",
    "    df_copy = df.copy()\n",
    "    def kurt(df):\n",
    "        result = df.kurt()\n",
    "        return result\n",
    "    def skew(df):\n",
    "        df_n=df.copy()\n",
    "        df_n = df[df.values>0]\n",
    "        return df_n.skew()\n",
    "    Employ_Behavior_Amount=df_copy.groupby(id_person)[amount].agg([\"count\",'sum','mean',\"median\",\"std\",\"max\",\"min\",skew,kurt])\n",
    "    Employ_Behavior_Amount=Employ_Behavior_Amount.rename(columns={'count': 'Total_Reimbursement_Times','sum':'Total_Amount','mean':'Average_Amount','std':'Std_Amount','max':'Max_Amount','min':'Min_Amount',\"median\":\"Median_Amount\",\"skew\":\"Skew_Amount\",\"kurt\":\"Kurt_Amount\"})\n",
    "    return Employ_Behavior_Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  支付方式部分 person_cash_ratio(df,id_person,payment_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行为人数据，采用现金和公司卡的比例\n",
    "\"\"\"\n",
    "id_person: 员工所在列的列名\n",
    "payment_methods: 支付方式列的列名\n",
    "\n",
    "输出：员工支付方式部分dataframe\n",
    "\"\"\"\n",
    "def person_cash_ratio(df,id_person,payment_methods):\n",
    "    df_copy=df.copy()\n",
    "    def ratio_count_cash(df):\n",
    "        result = df.value_counts()/df.count()\n",
    "        try:\n",
    "            number = result.loc['现金']\n",
    "        except:\n",
    "            number = 0\n",
    "        return number\n",
    "\n",
    "    def ratio_count_cards(df):\n",
    "        result = df.value_counts()/df.count()\n",
    "        try:\n",
    "            number = result.loc['公司卡']\n",
    "        except:\n",
    "            number = 0\n",
    "        return number\n",
    "\n",
    "    # 类型部分\n",
    "    Employ_Behavior_Payment=df_copy.groupby(id_person)[payment_methods].agg([ratio_count_cash,ratio_count_cards])\n",
    "\n",
    "    Employ_Behavior_Payment=Employ_Behavior_Payment.rename(columns={'ratio_count_cash': 'Payment_Cash_Ratio','ratio_count_cards':'Payment_Card_Ratio'})\n",
    "    return Employ_Behavior_Payment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 报销数据类型特征 person_expense_feature(df,id_person,expense_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行为人数据——每个人的报销数据类型特征比例\n",
    "\"\"\"\n",
    "id_person: 员工所在列的列名\n",
    "expense_type: 报销类型列的列名\n",
    "\n",
    "输出：员工报销类型部分dataframe\n",
    "\"\"\"\n",
    "def person_expense_feature(df,id_person,expense_type):\n",
    "    df_copy = df.copy()\n",
    "    def re1(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            name = result.loc['客户娱乐']\n",
    "        except:\n",
    "            name = 0\n",
    "        return name\n",
    "\n",
    "    def re2(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            number = result.loc[\"加班餐补\"]\n",
    "        except:\n",
    "            number = 0\n",
    "        return number\n",
    "\n",
    "    def re3(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            name = result.loc['会议']\n",
    "        except:\n",
    "            name = 0\n",
    "        return name\n",
    "\n",
    "    def re4(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            number = result.loc[\"租车费\"]\n",
    "        except:\n",
    "            number = 0\n",
    "        return number\n",
    "\n",
    "    def re5(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            name = result.loc['住宿']\n",
    "        except:\n",
    "            name = 0\n",
    "        return name\n",
    "\n",
    "    def re6(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            number = result.loc[\"HCP支付\"]\n",
    "        except:\n",
    "            number = 0\n",
    "        return number\n",
    "\n",
    "    def re7(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            name = result.loc['机票费']\n",
    "        except:\n",
    "            name = 0\n",
    "        return name\n",
    "\n",
    "    def re8(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            number = result.loc[\"翻译费\"]\n",
    "        except:\n",
    "            number = 0\n",
    "        return number\n",
    "\n",
    "    def re9(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            name = result.loc['地面交通']\n",
    "        except:\n",
    "            name = 0\n",
    "        return name\n",
    "\n",
    "    def re10(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            number = result.loc[\"停车费\"]\n",
    "        except:\n",
    "            number = 0\n",
    "        return number\n",
    "\n",
    "    def re11(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            name = result.loc['员工餐费']\n",
    "        except:\n",
    "            name = 0\n",
    "        return name\n",
    "\n",
    "    def re12(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            number = result.loc[\"运输费\"]\n",
    "        except:\n",
    "            number = 0\n",
    "        return number\n",
    "\n",
    "    def re13(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            number = result.loc[\"金融其他\"]\n",
    "        except:\n",
    "            number = 0\n",
    "        return number\n",
    "\n",
    "    def re14(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            name = result.loc['员工娱乐']\n",
    "        except:\n",
    "            name = 0\n",
    "        return name\n",
    "\n",
    "    def re15(df):\n",
    "        result = df.value_counts(sort=True)/df.count()\n",
    "        try:\n",
    "            number = result.loc[\"其他\"]\n",
    "        except:\n",
    "            number = 0\n",
    "        return number\n",
    "\n",
    "\n",
    "    # 类型部分\n",
    "    Employ_Behavior_Expense_type=df_copy.groupby(id_person)[expense_type].agg([re1,re2,re3,re4,re5,re6,re7,re8,re9,re10,re11,re12,re13,re14,re15])\n",
    "\n",
    "    Employ_Behavior_Expense_type=Employ_Behavior_Expense_type.rename(columns={'re1':'客户娱乐','re2':'加班餐补','re3':'会议','re4':'租车费','re5':'住宿','re6': 'HCP支付','re7': '机票费','re8':'翻译费','re9':'地面交通','re10':'停车费','re11':'员工餐费','re12': '运输费','re13':'金融其他','re14':'员工娱乐','re15':'其他'})\n",
    "    return Employ_Behavior_Expense_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 每一月的报销特征向量及其距离计算（三种方法）create_month_vector(df,data1,list_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成每月的报销费用占比形成向量，考察向量之间的关系与异常值——三种方法\n",
    "# 输入参数必须为索引是日期的df,data1为待插入的用户行为数据df\n",
    "\"\"\"\n",
    "df: 原始数据\n",
    "data1:用户特征行为表\n",
    "\"\"\"\n",
    "def create_month_vector(df,data1,list_cols):\n",
    "    company_copy = df\n",
    "    groups=company_copy[['Employee_Global_ID','Approved_Amount',\"Expense type\"]].groupby('Employee_Global_ID')\n",
    "\n",
    "    list_name=[]\n",
    "    list_cos=[]\n",
    "    n=0\n",
    "\n",
    "    for name,group in groups:\n",
    "        print(name,n)\n",
    "        n=n+1\n",
    "        group = pd.DataFrame(group)\n",
    "        list_cos.append(rexx(group))\n",
    "        list_name.append(name)\n",
    "\n",
    "    result = pd.DataFrame(columns=['Employee_Global_ID','distance_avg'])\n",
    "    result[\"Employee_Global_ID\"]=list_name\n",
    "    result[\"distance_avg\"]=list_cos\n",
    "    result = result.set_index(\"Employee_Global_ID\",drop=True)\n",
    "    result_1=pd.concat([data1,result],axis=1)\n",
    "    result_1.to_csv(r\"concat_final_version.csv\",encoding='gbk')\n",
    "    \n",
    "    def rexx(df):\n",
    "        total_frame=pd.DataFrame(df['Approved_Amount'].resample('M').sum().to_period('M'))#.iloc[:,0]\n",
    "        \"\"\"\n",
    "        #动态代码改写如下(未来提升算法速度以及提升代码重用性时可以进行改写，基本语法如下)：\n",
    "        #length = len(list_cols)\n",
    "        #for i in range():\n",
    "        #    local()[\"df\"+str(i)]=df[df[\"Expense type\"]==list_cols[i]]\n",
    "        \"\"\"\n",
    "        df_1 = df[df['Expense type']=='客户娱乐']\n",
    "        total_1=pd.DataFrame(df_1['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_1=total_1.rename(columns={'Approved_Amount':\"客户娱乐\"})\n",
    "        df_2 = df[df['Expense type']=='加班餐补']\n",
    "        total_2=pd.DataFrame(df_2['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_2=total_2.rename(columns={'Approved_Amount':\"加班餐补\"})\n",
    "        df_3 = df[df['Expense type']=='会议']\n",
    "        total_3=pd.DataFrame(df_3['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_3=total_3.rename(columns={'Approved_Amount':\"会议\"})\n",
    "        df_4 = df[df['Expense type']=='租车费']\n",
    "        total_4=pd.DataFrame(df_4['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_4=total_4.rename(columns={'Approved_Amount':\"租车费\"})\n",
    "        df_5 = df[df['Expense type']=='住宿']\n",
    "        total_5=pd.DataFrame(df_5['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_5=total_5.rename(columns={'Approved_Amount':\"住宿\"})\n",
    "\n",
    "        df_6 = df[df['Expense type']=='HCP支付']\n",
    "        total_6=pd.DataFrame(df_6['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_6=total_6.rename(columns={'Approved_Amount':\"HCP支付\"})\n",
    "        df_7 = df[df['Expense type']=='机票费']\n",
    "        total_7=pd.DataFrame(df_7['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_7=total_7.rename(columns={'Approved_Amount':\"机票费\"})\n",
    "        df_8 = df[df['Expense type']=='翻译费']\n",
    "        total_8=pd.DataFrame(df_8['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_8=total_8.rename(columns={'Approved_Amount':\"翻译费\"})\n",
    "        df_9 = df[df['Expense type']=='地面交通']\n",
    "        total_9=pd.DataFrame(df_9['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_9=total_9.rename(columns={'Approved_Amount':\"地面交通\"})\n",
    "        df_10 = df[df['Expense type']=='停车费']\n",
    "        total_10=pd.DataFrame(df_10['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_10=total_10.rename(columns={'Approved_Amount':\"停车费\"})\n",
    "\n",
    "        df_11 = df[df['Expense type']=='员工餐费']\n",
    "        total_11=pd.DataFrame(df_11['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_11=total_11.rename(columns={'Approved_Amount':\"员工餐费\"})\n",
    "        df_12 = df[df['Expense type']=='运输费']\n",
    "        total_12=pd.DataFrame(df_12['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_12=total_12.rename(columns={'Approved_Amount':\"运输费\"})\n",
    "        df_13 = df[df['Expense type']=='金融其他']\n",
    "        total_13=pd.DataFrame(df_13['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_13=total_13.rename(columns={'Approved_Amount':\"金融其他\"})\n",
    "        df_14 = df[df['Expense type']=='员工娱乐']\n",
    "        total_14=pd.DataFrame(df_14['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_14=total_14.rename(columns={'Approved_Amount':\"员工娱乐\"})\n",
    "        df_15 = df[df['Expense type']=='其他']\n",
    "        total_15=pd.DataFrame(df_15['Approved_Amount'].resample('M').sum().to_period('M'))\n",
    "        total_15=total_15.rename(columns={'Approved_Amount':\"其他\"})\n",
    "\n",
    "        total_frame_all = pd.concat([total_frame,total_1,total_2,total_3,total_4,total_5,total_6,total_7,total_8,total_9,total_10,total_11,total_12,total_13,total_14,total_15],axis=1)\n",
    "\n",
    "        total_frame_all['客户娱乐']=total_frame_all['客户娱乐']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['加班餐补']=total_frame_all['加班餐补']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['会议']=total_frame_all['会议']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['租车费']=total_frame_all['租车费']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['住宿']=total_frame_all['住宿']/total_frame_all['Approved_Amount']\n",
    "\n",
    "        total_frame_all['HCP支付']=total_frame_all['HCP支付']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['机票费']=total_frame_all['机票费']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['翻译费']=total_frame_all['翻译费']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['地面交通']=total_frame_all['地面交通']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['停车费']=total_frame_all['停车费']/total_frame_all['Approved_Amount']\n",
    "\n",
    "        total_frame_all['员工餐费']=total_frame_all['员工餐费']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['运输费']=total_frame_all['运输费']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['金融其他']=total_frame_all['金融其他']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['员工娱乐']=total_frame_all['员工娱乐']/total_frame_all['Approved_Amount']\n",
    "        total_frame_all['其他']=total_frame_all['其他']/total_frame_all['Approved_Amount']\n",
    "\n",
    "\n",
    "        total_frame_all=total_frame_all.fillna(0)\n",
    "        result_avg=pd.DataFrame(total_frame_all.mean())\n",
    "        result_avg = result_avg.T\n",
    "        total_frame_all = total_frame_all.append(result_avg)\n",
    "        length = len(total_frame_all)\n",
    "        result_array=np.array(total_frame_all)\n",
    "        #print(result_array)\n",
    "\n",
    "        \"\"\"\n",
    "        算法1：距离平均\n",
    "        \"\"\"\n",
    "        #norm_list = []\n",
    "        #for i in range(0,length-1):\n",
    "            #print(result_array[length-1])\n",
    "            #print(item)\n",
    "        #    norm_list.append(np.around(np.linalg.norm(result_array[i]-result_array[length-1]),decimals = 100))\n",
    "            #print(temp)\n",
    "        #length = len(cosine_similarity)\n",
    "        #print(cosine_similarity.describe)\n",
    "        #print(cosine_similarity)\n",
    "        #avg_norm=np.around(np.mean(norm_list), decimals=100) \n",
    "        #print(avg_norm)\n",
    "        #return avg_norm, result_array\n",
    "\n",
    "        \"\"\"\n",
    "        算法2：余弦相似度\n",
    "        \"\"\"\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        cosine_similarity=np.around(cosine_similarity(result_array),decimals=100)\n",
    "        cosine_similarity = pd.DataFrame(cosine_similarity)\n",
    "        avg_cosine=np.mean(cosine_similarity[length-1])\n",
    "        #print(avg_cosine)\n",
    "        return avg_cosine\n",
    "\n",
    "        \"\"\"\n",
    "        算法3：几何距离\n",
    "        \"\"\"\n",
    "        #norm_list = []\n",
    "        #for i in range(0,length-1):\n",
    "        #    item = result_array[i]\n",
    "        #    temp=item-result_array[length-1]\n",
    "        #    norm_list.append(np.around(np.linalg.norm(temp),decimals=100))\n",
    "        #length = len(cosine_similarity)\n",
    "        #print(cosine_similarity.describe)\n",
    "        #print(cosine_similarity)\n",
    "        #from scipy.stats import gmean\n",
    "        #avg_norm_g=gmean(norm_list)\n",
    "        #return avg_norm_g\n",
    "    return result1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 是否驳回 person_approve_feature(df,id_person,approve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 报销人数据——是否有过被驳回经历\n",
    "\"\"\"\n",
    "id_person: 员工所在列的列名\n",
    "approve: 是否同意列的列名\n",
    "\n",
    "输出：是否同意列部分dataframe\n",
    "\"\"\"\n",
    "def person_approve_feature(df,id_person,approve):\n",
    "    df_copy = df.copy()\n",
    "    def whether_all_approved(df):\n",
    "        list_neg = ['Submitted & Pending Approval','Approved & In Accounting Review','Not Submitted', 'Sent Back to Employee']\n",
    "        df_list=list(df)\n",
    "        number1 = df_list.count(\"Submitted & Pending Approval\")\n",
    "        number2 = df_list.count('Approved & In Accounting Review')\n",
    "        number3 = df_list.count('Not Submitted')\n",
    "        number4 = df_list.count('Sent Back to Employee')\n",
    "        total = number1+number2+number3+number4\n",
    "        if total != 0:\n",
    "            return total\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def whether_all_approved_ratio(df):\n",
    "        list_neg = ['Submitted & Pending Approval','Approved & In Accounting Review','Not Submitted', 'Sent Back to Employee']\n",
    "        df_list=list(df)\n",
    "        number1 = df_list.count(\"Submitted & Pending Approval\")\n",
    "        number2 = df_list.count('Approved & In Accounting Review')\n",
    "        number3 = df_list.count('Not Submitted')\n",
    "        number4 = df_list.count('Sent Back to Employee')\n",
    "        total = number1+number2+number3+number4\n",
    "        result = total/len(df_list)\n",
    "        return result\n",
    "\n",
    "    # 类型部分\n",
    "    Employ_Behavior_Approval_Status=df_copy.groupby(id_person)[approve].agg([whether_all_approved,whether_all_approved_ratio])\n",
    "\n",
    "    Employ_Behavior_Approval_Status=Employ_Behavior_Approval_Status.rename(columns={'whether_all_approved':\"Status_Not_Approved_Num\",'whether_all_approved_ratio':'Status_Not_Approved_Ratio'})\n",
    "    return Employ_Behavior_Approval_Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 报销参与人数据部分 person_attendee_feature(df,id_person,attendee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行为人数据——报销参与人数据部分\n",
    "def person_attendee_feature(df,id_person,attendee):\n",
    "    df_copy = df.copy()\n",
    "    Employ_Behavior_Attendee_Amount=df_copy.groupby(id_person)[attendee].agg([\"median\",'std','max'])\n",
    "    Employ_Behavior_Attendee_Amount=Employ_Behavior_Attendee_Amount.rename(columns={'median': 'Reimbursement_Attendee_Median','std':'Reimbursement_Attendee_Std','max':'Reimbursement_Attendee_max'})\n",
    "    return Employ_Behavior_Attendee_Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时间部分特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始日期、总计报销时长、平均时间间隔 person_time_feature(df,id_person,datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行为人数据——时间部分特征\n",
    "\"\"\"\n",
    "id_person: 员工所在列的列名\n",
    "datetime: 日期列的列名\n",
    "\n",
    "输出：日期列部分dataframe\n",
    "\"\"\"\n",
    "def person_time_feature(df,id_person,datetime):\n",
    "    df_copy = df.copy()\n",
    "    def range_date(df):\n",
    "        result = (df.max()-df.min()).days\n",
    "        return result\n",
    "\n",
    "\n",
    "    def avg_range_date(df):\n",
    "        result = (df.max()-df.min()).days/(df.count()-1)\n",
    "        return result\n",
    "\n",
    "    # 类型部分\n",
    "    df_copy['datetime']=pd.to_datetime(company[df_copy])\n",
    "    Employ_Behavior_Datetime=df_copy.groupby(id_person)['datetime'].agg([\"min\",range_date,avg_range_date])\n",
    "\n",
    "    Employ_Behavior_Datetime=Employ_Behavior_Datetime.rename(columns={'min':\"Beginning_Date\",'range_date':\"Reimbursement_Day_Range\",'avg_range_date':\"Reimbursement_Avg_Interval\"})\n",
    "    return Employ_Behavior_Datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 每月的平均数据 person_month_statistic(df,id_person,datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 报销人数据——每月的平均时间数据\n",
    "\"\"\"\n",
    "id_person: 员工所在列的列名\n",
    "datetime: 日期列的列名\n",
    "\n",
    "输出：日期列部分dataframe\n",
    "\"\"\"\n",
    "def person_month_statistic(df,id_person,datetime):\n",
    "    company = df.copy()\n",
    "    # 按月统计\n",
    "    company_copy=company.copy()\n",
    "    company_copy['datetime']=pd.to_datetime(company[datetime])\n",
    "    company_copy.set_index('datetime')\n",
    "    company_copy=company_copy.set_index('datetime')\n",
    "    def month_statistic(df):\n",
    "        result=df.resample('M').sum()\n",
    "        result_performance = result.mean()\n",
    "        return result_performance\n",
    "\n",
    "    def month_statistic_2(df):\n",
    "        result=df.resample('M').sum()\n",
    "        result_performance = result.std()\n",
    "        return result_performance\n",
    "\n",
    "    def month_statistic_3(df):\n",
    "        result=df.resample('M').count()\n",
    "        result_performance = result.mean()\n",
    "        return result_performance\n",
    "\n",
    "    def month_statistic_4(df):\n",
    "        result=df.resample('M').count()\n",
    "        result_performance = result.std()\n",
    "        return result_performance\n",
    "\n",
    "    Employ_Behavior_Datetime_avg=company_copy.groupby(id_person)['Approved_Amount'].agg([month_statistic_3,month_statistic_4,month_statistic,month_statistic_2])\n",
    "\n",
    "    Employ_Behavior_Datetime_avg=Employ_Behavior_Datetime_avg.rename(columns={'month_statistic_3':\"Avg_Count_Per_Month\",\"month_statistic_4\":\"Std_Count_Per_Month\",'month_statistic':\"Avg_Per_Month\",'month_statistic_2':\"Std_Per_Month\"})\n",
    "    return Employ_Behavior_Datetime_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 报销频率，报销速度, 分部门，与报销类型 person_add_other_feature(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 报销人数据——其他特征数据\n",
    "def person_add_other_feature(df):\n",
    "    Employ_Behavior = df.copy()\n",
    "    # 报销频率\n",
    "    Employ_Behavior['Reimbursement_Frequency']=Employ_Behavior['Total_Reimbursement_Times']/Employ_Behavior['Reimbursement_Day_Range']\n",
    "    # 报销平均时长\n",
    "    Employ_Behavior['Reimbursement_Avg_Amount_Daily']=Employ_Behavior['Total_Amount']/Employ_Behavior['Reimbursement_Day_Range']\n",
    "    return Employ_Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols=['客户娱乐', '加班餐补', '会议', '租车费', '住宿', 'HCP支付', '机票费',\n",
    "       '翻译费', '地面交通', '停车费', '员工餐费', '运输费', '金融其他', '员工娱乐', '其他']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Employ_Behavior_Expense_type = Employ_Behavior[['客户娱乐', '加班餐补', '会议', '租车费', '住宿', 'HCP支付', '机票费',\n",
    "       '翻译费', '地面交通', '停车费', '员工餐费', '运输费', '金融其他', '员工娱乐', '其他','BU']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_others=Employ_Behavior_Expense_type[Employ_Behavior_Expense_type['BU']=='其他部门']\n",
    "test_sales=Employ_Behavior_Expense_type[Employ_Behavior_Expense_type['BU']=='销售']\n",
    "test_purchase=Employ_Behavior_Expense_type[Employ_Behavior_Expense_type['BU']=='采购']\n",
    "test_market=Employ_Behavior_Expense_type[Employ_Behavior_Expense_type['BU']=='市场']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_others_b=Employ_Behavior[Employ_Behavior['BU']=='其他部门']\n",
    "test_sales_b=Employ_Behavior[Employ_Behavior['BU']=='销售']\n",
    "test_purchase_b=Employ_Behavior[Employ_Behavior['BU']=='采购']\n",
    "test_market_b=Employ_Behavior[Employ_Behavior['BU']=='市场']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 异常值检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 孤立森林 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def IsolationForest(df,df2,list_col,contamination):\n",
    "    \n",
    "    from sklearn.ensemble import IsolationForest\n",
    "\n",
    "    rng = np.random.RandomState(42)\n",
    "\n",
    "    df_n = df[list_col]\n",
    "\n",
    "    cov = IsolationForest(n_estimators=100,behaviour='new', max_samples=256,random_state=rng, contamination=contamination).fit(df_n)\n",
    "\n",
    "    test_result = cov.predict(df_n)\n",
    "\n",
    "    print('预测完成')\n",
    "    x_test_copy = df2.copy()\n",
    "    x_test_copy['label'] = test_result\n",
    "    normal_test_data = x_test_copy[x_test_copy['label'] == 1]\n",
    "    abnormal_test_data = x_test_copy[x_test_copy['label'] == -1]\n",
    "#     abnormal_test_data.to_csv(r\"abnnormal_test_data.csv\",encoding='gbk')\n",
    "#     abnormal_test_data.describe().to_csv(r\"abnnormal_test_data_des\",encoding='gbk')\n",
    "    return abnormal_test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数解释\n",
    "class sklearn.ensemble.IsolationForest（n_estimators = 100，max_samples ='auto'，contamination ='legacy'，max_features = 1.0，bootstrap = False，n_jobs = None，behavior ='old'，random_state = None，verbose = 0 ）\n",
    "\n",
    "n_estimators ： int，optional（默认值= 100）\n",
    "整体中基本估算器的数量。配置iTree树的多少\n",
    " \n",
    "max_samples ： int或float，optional（default =“auto”）\n",
    "从X中抽取的样本数量，用于训练每个基本估算器。\n",
    "如果是int，则绘制max_samples样本。\n",
    "如果是float，则绘制max_samples * X.shape [0]样本。\n",
    "如果是“auto”，则max_samples = min（256，n_samples）。\n",
    "如果max_samples大于提供的样本数，则所有样本将用于所有树（无采样）。\n",
    " \n",
    "contamination ： float（0.，0.5），可选（默认值= 0.1）\n",
    "数据集的污染量，即数据集中异常值的比例。在拟合时用于定义决策函数的阈值。如果是“自动”，则确定决策函数阈值，如原始论文中所示。\n",
    " \n",
    "在版本0.20中更改：默认值contamination将从0.20更改为'auto'0.22。\n",
    " \n",
    "max_features ： int或float，可选（默认值= 1.0）\n",
    "从X绘制以训练每个基本估计器的特征数。\n",
    " \n",
    "如果是int，则绘制max_features特征。\n",
    "如果是float，则绘制max_features * X.shape [1]特征。\n",
    "bootstrap ： boolean，optional（default = False）\n",
    "如果为True，则单个树适合于通过替换采样的训练数据的随机子集。如果为假，则执行未更换的采样。\n",
    " \n",
    "n_jobs ： int或None，可选（默认=无）\n",
    "适合和预测并行运行的作业数。 None除非在joblib.parallel_backend上下文中，否则表示1 。 -1表示使用所有处理器。\n",
    " \n",
    "random_state ： int，RandomState实例或None，可选（默认=无）\n",
    "如果是int，则random_state是随机数生成器使用的种子; 如果是RandomState实例，则random_state是随机数生成器; 如果没有，随机数生成器所使用的RandomState实例np.random。\n",
    " \n",
    "verbose ： int，optional（默认值= 0）\n",
    "控制树构建过程的详细程度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOF\n",
    "def localoutlierfactor(data, predict, k):\n",
    "    from sklearn.neighbors import LocalOutlierFactor\n",
    "    clf = LocalOutlierFactor(n_neighbors=k + 1, algorithm='auto', contamination=0.1, n_jobs=-1)\n",
    "    clf.fit(data)\n",
    "    #     # 记录 k 邻域距离\n",
    "    predict['k distances'] = clf.kneighbors(predict)[0].max(axis=1)\n",
    "    # 记录 LOF 离群因子，做相反数处理\n",
    "    predict['local outlier factor'] = -clf._decision_function(predict.iloc[:, :-1])\n",
    "    return predict\n",
    "\n",
    "\n",
    "def plot_lof(result, method):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "    plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "    plt.figure(figsize=(8, 4)).add_subplot(111)\n",
    "    plt.scatter(result[result['local outlier factor'] > method].index,\n",
    "                result[result['local outlier factor'] > method]['local outlier factor'], c='red', s=50,\n",
    "                marker='.', alpha=None,\n",
    "                label='离群点')\n",
    "    plt.scatter(result[result['local outlier factor'] <= method].index,\n",
    "                result[result['local outlier factor'] <= method]['local outlier factor'], c='black', s=50,\n",
    "                marker='.', alpha=None, label='正常点')\n",
    "    plt.hlines(method, -2, 2 + max(result.index), linestyles='--')\n",
    "    plt.xlim(-2, 2 + max(result.index))\n",
    "    plt.title('LOF局部离群点检测', fontsize=13)\n",
    "    plt.ylabel('局部离群因子', fontsize=15)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def lof(data1, data2,list_col, predict=None, k=5):\n",
    "    data = data1[list_col]\n",
    "    import pandas as pd\n",
    "    # 判断是否传入测试数据，若没有传入则测试数据赋值为训练数据\n",
    "    try:\n",
    "        if predict == None:\n",
    "            predict = data.copy()\n",
    "    except Exception:\n",
    "        pass\n",
    "    predict = pd.DataFrame(predict)\n",
    "    # 计算 LOF 离群因子\n",
    "    predict = localoutlierfactor(data, predict, k)\n",
    "    print('计算离群因子完成')\n",
    "    print('  ')\n",
    "    data2['local outlier factor'] =  predict['local outlier factor']\n",
    "\n",
    "    # 根据阈值划分离群点与正常点\n",
    "    outliers = data2[data2['local outlier factor'] > 1].sort_values(by='local outlier factor')\n",
    "    inliers = data2[data2['local outlier factor'] <= 1].sort_values(by='local outlier factor')\n",
    "    outliers.to_csv(r\"outliers.csv\",encoding='gbk')\n",
    "    outliers.describe().to_csv(r\"outlier_des.csv\",encoding='gbk')\n",
    "    return outliers,inliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
